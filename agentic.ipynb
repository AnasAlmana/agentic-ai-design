{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read an image & Brand Info -> convert to base64 >> simple python code\n",
    "\n",
    "agentic starts here:\n",
    "1. send to openai for image detailed description ->\n",
    "2. send description to creative model for creative ideas prompts -> \n",
    "3. send image, brand info, creative ideas prompts to creative model for design ->\n",
    "4. covert image back from base64 -> \n",
    "5. Compress image to < 1MB & 24 Bit depth & Resize to 1080x1920 for TIKTOK ->\n",
    "6. save image & save design prompt.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read image and brand profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DESCRIPTION_PROMPT_TEMPLATE = \"\"\" \n",
    "Describe the image in detail, focus on the main subject in the image usually in the center, \n",
    "extract all brand info like brand name and slogan if applicable. Make sure to include all details of the image.\n",
    "\"\"\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def describe_image(base64_image: str) -> str:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \"type\": \"input_text\", \"text\": IMAGE_DESCRIPTION_PROMPT_TEMPLATE },\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.output_text\n",
    "image_description_runnable = RunnableLambda(describe_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Give the LLM a system instruction for creativity\n",
    "creative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a creative AI for marketing.\"),\n",
    "    (\"user\", \n",
    "     \"Given an image description, generate 3 imaginative image ideas for image-to-image model, the ideas should be for marketing and online presence.\"\n",
    "     \"Here is the image description:\\n\\n{description}\")\n",
    "])\n",
    "# Combine prompt + model into a runnable\n",
    "creative_runnable = creative_prompt | creative_llm\n",
    "\n",
    "\n",
    "chain = image_description_runnable | creative_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three imaginative image ideas for marketing and online presence based on the provided image description:\n",
      "\n",
      "1. **Cultural Feast Experience**:\n",
      "   Create an inviting outdoor setting at sunset, showcasing the mouthwatering platter as the centerpiece of a communal feast. Surround the platter with colorful decorative cushions and traditional woven textiles. Add rustic wooden tables adorned with flickering lanterns and small floral arrangements. Include diverse groups of friends and family joyfully sharing the meal, laughter echoing. Captions can play with themes of togetherness, heritage, and the joy of sharing traditional food. Utilize hashtags like #CulturalFeast and #FoodStories to connect with audiences seeking authentic experiences.\n",
      "\n",
      "2. **Step-by-Step Culinary Journey**:\n",
      "   Design a multi-image carousel that takes viewers through the cooking process, from raw ingredients to the finished platter. Start with vibrant images of spices, herbs, and fresh ingredients being artfully arranged. Progress through stages of cooking â€“ marinating the chicken, boiling the rice, and assembling. Conclude with the final presentation shot of the beautifully garnished platter. Each image can be accompanied by engaging captions that invite followers to try the recipe, along with tips from the chef. Consider using hashtags like #CulinaryJourney and #FromScratch to attract food enthusiasts.\n",
      "\n",
      "3. **A Taste of Tradition**:\n",
      "   Craft an elegant, styled flat lay that incorporates the platter with additional elements representing cultural heritage. Place the platter in the center, surrounded by intricately designed serving utensils, decorative spices in small bowls, and handwritten recipe cards that share the history of the dish. Highlight the textures and colors of the ingredients, creating an aesthetically pleasing layout. Overlay an inspiring quote about food as a bridge between cultures. Use hashtags like #TasteOfTradition and #CulinaryHeritage to engage users who appreciate authentic, cultural content.\n"
     ]
    }
   ],
   "source": [
    "# Getting the Base64 string\n",
    "image_path = \"images/img.jpg\"\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "# Run chain\n",
    "result = chain.invoke(base64_image)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three imaginative image ideas for marketing and online presence based on the provided image description:\n",
      "\n",
      "1. **Cultural Feast Celebration**:\n",
      "   - Create a vibrant scene depicting a communal dining table set outdoors, adorned with intricate Middle Eastern decor. The focal point is the large tray of Kabsa, surrounded by family and friends enjoying the meal. Fresh salads, dips, and drinks are artfully arranged on the table, promoting a sense of community and celebration. Soft lighting during golden hour can enhance the ambiance.\n",
      "\n",
      "2. **Chef's Special Showcase**:\n",
      "   - Illustrate a close-up of a chef in traditional attire, skillfully garnishing the Kabsa with fresh herbs and lemon slices. Incorporate elements that highlight the cooking process, such as spices and fresh ingredients scattered around. The background can feature a glowing kitchen atmosphere, emphasizing authenticity and craftsmanship in traditional Middle Eastern cuisine.\n",
      "\n",
      "3. **Flavor Journey with Pairings**:\n",
      "   - Design a split-image concept featuring the Kabsa on one side, paired with a colorful array of sauces in beautiful small cups on the other side. Include a close-up of the dessert (Kunafa or Basbousa) beautifully plated next to the rice dish. Use bright backgrounds to celebrate the vibrant colors of the food, making it visually appealing for social media and food blogs, while inviting viewers to explore flavor combinations.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# --- Step 1: Image -> Description ---\n",
    "IMAGE_DESCRIPTION_PROMPT_TEMPLATE = \"\"\" \n",
    "Describe the image in detail, focus on the main subject in the image usually in the center, \n",
    "extract all brand info like brand name and slogan if applicable. Make sure to include all details of the image.\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def describe_image(base64_image: str) -> dict:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",  # vision-capable\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": IMAGE_DESCRIPTION_PROMPT_TEMPLATE},\n",
    "                    {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    # Return dict so we can pass both description + original image forward\n",
    "    return {\n",
    "        \"description\": response.output_text,\n",
    "        \"base64_image\": base64_image\n",
    "    }\n",
    "\n",
    "image_description_runnable = RunnableLambda(describe_image)\n",
    "\n",
    "# --- Step 2: Creative Ideas (use description + image) ---\n",
    "creative_llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a creative AI for marketing.\"),\n",
    "    (\"user\", \n",
    "     \"Given image description AND the actual image, generate 3 imaginative image ideas for image-to-image model, the ideas should be for marketing and online presence.\"\n",
    "     \"Here is the image description:\\n\\n{description}\\n\\n\"),\n",
    "    # attach the raw image again\n",
    "    (\"user\", [\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{base64_image}\"}}\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Combine prompt + LLM\n",
    "creative_runnable = creative_prompt | creative_llm\n",
    "\n",
    "# --- Build full chain ---\n",
    "chain = image_description_runnable | creative_runnable\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/img.jpg\"\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "result = chain.invoke(base64_image)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Hereâ€™s a detailed description of such an image:\n",
      "\n",
      "A large, round metal tray brimming with *Kabsa*â€”golden rice crowned with succulent pieces of spiced chicken, roasted nuts, and raisinsâ€”takes center stage atop a red-and-white checkered picnic blanket spread over lush green grass. Around the tray, smaller bowls overflow with colorful salads: a fresh tabbouleh shimmering with chopped parsley and tomato; creamy hummus swirled with olive oil and paprika; and a bright cucumber-yogurt salad. Stacks of warm, pillowy pita and crusty bread sit ready for tearing and sharing.\n",
      "\n",
      "Glasses and pitchers of cool drinksâ€”perhaps mint lemonade and chilled waterâ€”sparkle in the sunlight. People, a diverse group of friends and family, are seated cross-legged and barefoot, their hands reaching toward the tray, passing platters, laughing, and enjoying each otherâ€™s company. Above, the sky is bright and clear, with sunlight dappled through a few leaves, completing the joyful, communal atmosphere of the picnic scene.\n",
      "\n",
      "---\n",
      "\n",
      "If youâ€™d like this as a prompt for generating an image (e.g., for Midjourney, DALL-E, etc.), hereâ€™s a version you can copy:\n",
      "\n",
      "**Prompt:**  \n",
      "A vibrant outdoor picnic scene on a grassy field, featuring a large, round metal tray of Kabsa rice topped with spiced chicken and garnished with nuts and raisins, placed on a red-and-white checkered blanket. Surrounding the tray are colorful bowls of salad (tabbouleh, hummus, cucumber-yogurt salad), stacks of fresh pita and bread, and glasses of cool drinks. Groups of people, smiling and joyful, share and enjoy the meal together, with sunlight and a clear blue sky overhead.\n",
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "string argument should contain only ASCII characters",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\base64.py:37\u001b[0m, in \u001b[0;36m_bytes_from_decode_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\u2019' in position 15: ordinal not in range(128)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 103\u001b[0m\n\u001b[0;32m    100\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/img.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# path to your input image\u001b[39;00m\n\u001b[0;32m    101\u001b[0m base64_image \u001b[38;5;241m=\u001b[39m encode_image(image_path)\n\u001b[1;32m--> 103\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase64_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)  \u001b[38;5;66;03m# dict with {\"prompt1\": <image_url>, \"prompt2\": ..., \"prompt3\": ...}\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\agentic-ai-design\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3049\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3048\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3049\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3050\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Projects\\agentic-ai-design\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:4781\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4767\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[0;32m   4768\u001b[0m \n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4778\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[0;32m   4779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4782\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4783\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4784\u001b[0m         ensure_config(config),\n\u001b[0;32m   4785\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4786\u001b[0m     )\n\u001b[0;32m   4787\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4788\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "File \u001b[1;32mc:\\Projects\\agentic-ai-design\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:1938\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1934\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   1936\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1937\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1938\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1939\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m                 func,\n\u001b[0;32m   1941\u001b[0m                 input_,\n\u001b[0;32m   1942\u001b[0m                 config,\n\u001b[0;32m   1943\u001b[0m                 run_manager,\n\u001b[0;32m   1944\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1945\u001b[0m             ),\n\u001b[0;32m   1946\u001b[0m         )\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1948\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Projects\\agentic-ai-design\\venv\\lib\\site-packages\\langchain_core\\runnables\\config.py:429\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    428\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Projects\\agentic-ai-design\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:4639\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4637\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4639\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4640\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, input_, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4641\u001b[0m     )\n\u001b[0;32m   4642\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32mc:\\Projects\\agentic-ai-design\\venv\\lib\\site-packages\\langchain_core\\runnables\\config.py:429\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    428\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[42], line 84\u001b[0m, in \u001b[0;36mgenerate_images_from_prompts\u001b[1;34m(ai_message)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(b64_image)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(b64_image))\n\u001b[1;32m---> 84\u001b[0m image_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mbase64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb64decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb64_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Save image to file\u001b[39;00m\n\u001b[0;32m     87\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\base64.py:80\u001b[0m, in \u001b[0;36mb64decode\u001b[1;34m(s, altchars, validate)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mb64decode\u001b[39m(s, altchars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode the Base64 encoded bytes-like object or ASCII string s.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    Optional altchars must be a bytes-like object or ASCII string of length 2\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    in the input result in a binascii.Error.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43m_bytes_from_decode_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m altchars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         altchars \u001b[38;5;241m=\u001b[39m _bytes_from_decode_data(altchars)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\base64.py:39\u001b[0m, in \u001b[0;36m_bytes_from_decode_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring argument should contain only ASCII characters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, bytes_types):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[1;31mValueError\u001b[0m: string argument should contain only ASCII characters"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# --- Helper: encode image to base64 ---\n",
    "def encode_image(image_path: str) -> str:\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# --- OpenAI client ---\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# --- Step 1: Image -> Description ---\n",
    "IMAGE_DESCRIPTION_PROMPT_TEMPLATE = \"\"\" \n",
    "Describe the image in detail, focus on the main subject in the image usually in the center, \n",
    "extract all brand info like brand name and slogan if applicable. Make sure to include all details of the image.\n",
    "\"\"\"\n",
    "\n",
    "def describe_image(base64_image: str) -> dict:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",  # vision-capable\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": IMAGE_DESCRIPTION_PROMPT_TEMPLATE},\n",
    "                    {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return {\n",
    "        \"description\": response.output_text,\n",
    "        \"base64_image\": base64_image\n",
    "    }\n",
    "\n",
    "image_description_runnable = RunnableLambda(describe_image)\n",
    "\n",
    "# --- Step 2: Description + Image -> Creative Prompts ---\n",
    "creative_llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a creative AI for marketing.\"),\n",
    "    (\"user\", \n",
    "     \"Here is the image description:\\n\\n{description}\\n\\n\"\n",
    "     \"Based on this description AND the actual image, generate 3 imaginative \"\n",
    "     \"**image generation prompts** to create new marketing visuals. \"\n",
    "     \"Return only JSON with keys: prompt1, prompt2, prompt3. \"\n",
    "     \"Do NOT include any extra text or explanations.\"),\n",
    "    (\"user\", [\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{base64_image}\"}}\n",
    "    ])\n",
    "])\n",
    "\n",
    "\n",
    "creative_runnable = creative_prompt | creative_llm\n",
    "import re\n",
    "\n",
    "def parse_json_safe(text: str) -> dict:\n",
    "    # Extract {...} from the string\n",
    "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return json.loads(match.group())\n",
    "    else:\n",
    "        raise ValueError(\"No JSON found in AI output\")\n",
    "\n",
    "# --- Step 3: Prompts -> Images using GPT-4.1 ---\n",
    "def generate_images_from_prompts(ai_message: AIMessage) -> dict:\n",
    "    prompts_json = parse_json_safe(ai_message.content)\n",
    "    images = {}\n",
    "    for key, prompt in prompts_json.items():\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=[{\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": prompt}]}],\n",
    "        )\n",
    "        # GPT-4.1 returns base64 string in resp.output[0].content[0].text\n",
    "        b64_image = resp.output[0].content[0].text\n",
    "        print(b64_image)\n",
    "        print(type(b64_image))\n",
    "        image_bytes = base64.b64decode(b64_image)\n",
    "        \n",
    "        # Save image to file\n",
    "        file_path = f\"{key}.png\"\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(image_bytes)\n",
    "        \n",
    "        images[key] = file_path\n",
    "    return images\n",
    "\n",
    "image_generation_runnable = RunnableLambda(generate_images_from_prompts)\n",
    "\n",
    "# --- Full Chain: Image -> Description -> Creative Prompts -> Generated Images ---\n",
    "chain = image_description_runnable | creative_runnable | image_generation_runnable\n",
    "\n",
    "# --- Run the chain ---\n",
    "image_path = \"images/img.jpg\"  # path to your input image\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "result = chain.invoke(base64_image)\n",
    "print(result)  # dict with {\"prompt1\": <image_url>, \"prompt2\": ..., \"prompt3\": ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
